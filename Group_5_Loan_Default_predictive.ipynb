{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group 5_Loan_Default_predictive.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0LJ4R5uEVZr"
      },
      "source": [
        "# CALLING LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder as onehot\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn import set_config\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHH_w98VNnBf"
      },
      "source": [
        "#MOUNTING G DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXZt8qdRPRP7"
      },
      "source": [
        "# SETTING UP PATH OF ZIP FILE\n",
        "path =  \"/content/drive/MyDrive/\" +\"Loan_default_train_v2.csv.zip\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZwR0z48_PY"
      },
      "source": [
        "#READING CSV FILE SHOWING INCLUION OF LOSS KEY\n",
        "train = pd.read_csv(\n",
        "                     path,\n",
        "                     header=0,  # First row is header-row\n",
        "                    )\n",
        "\n",
        "train.dtypes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ygVyWshDLOm"
      },
      "source": [
        "abc=train.copy()\n",
        "print(train.shape)    #Number of rows and columns respectively\n",
        "print()\n",
        "train.tail(10)\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EojXjnXkddtq"
      },
      "source": [
        "#CLEANING DATA\n",
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rreyeCdlt0xL"
      },
      "source": [
        "train.dropna(inplace =True)\n",
        "train.shape                   #ALMOST HALF ROWS REMOVED DUE TO PRESENCE OF NULL VALUES\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYBUEXlGL25p"
      },
      "source": [
        "print(train.info())   # We can observe \"object\" datatypes(19) of keys(columns) and try to remove them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPOmpJFpuxz0"
      },
      "source": [
        "Object_removal = train.select_dtypes(include=['object'])\n",
        "print(Object_removal.head(20))\n",
        "\n",
        "# FOR loop for checking datatype of object type and removing them\n",
        "\n",
        "for i in train.select_dtypes(include=['object']).columns:\n",
        "    train.drop(labels=i, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlhBlDD8mEKb"
      },
      "source": [
        "\n",
        "print(train.shape)   # DATA ready for splitting into testing and training where further model can be applied\n",
        "print(train.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sEwqjmXedFF"
      },
      "source": [
        "\n",
        " MODELING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfzAbSecZ1ra"
      },
      "source": [
        "#DATA SPLITTING \n",
        "X = train.iloc[:,1:751]\n",
        "Y = train.iloc[:,751]                   # Selection of Loss Column as hyperparameter\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)    #20 percent proportion of data in testing data split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqigl3y7UgcG"
      },
      "source": [
        "# APPLYING RANDOM FOREST MODEL\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=50)\n",
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd0oSVFeY-4x"
      },
      "source": [
        "model.score(X_test,Y_test)    #Accuracy of the model determined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpBF_h-sqFrc"
      },
      "source": [
        "\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))   #RMSE which comes near 15% \n",
        "print(\"The mean squared error (MSE) on test set: {}\".format(mse))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}